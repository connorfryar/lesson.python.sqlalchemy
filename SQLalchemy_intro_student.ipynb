{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to SQLalchemy\n",
    "[documentation](https://docs.sqlalchemy.org/en/20/)\n",
    "### Overview & Core Comps\n",
    "The SQLAlchemy SQL Toolkit and Object Relational Mapper is a comprehensive set of tools for working with databases and Python. It has several distinct areas of functionality which can be used individually or combined together. Its major components are illustrated below, with component dependencies organized into layers:\n",
    "\n",
    "<img src=\"https://docs.sqlalchemy.org/en/20/_images/sqla_arch_small.png\" alt=\"ARCH IMG MISSING\" height=\"400\" onerror=\"this.src='./imgs/arch_overview.png'; this.onerror=null;\">\n",
    "\n",
    "Above, the two most significant front-facing portions of SQLAlchemy are the Object Relational Mapper (ORM) and the Core.\n",
    "\n",
    "# How does it work\n",
    "\n",
    "<img src=\"./imgs/ORM.png\" alt=\"ORM IMG MISSING\" height = \"400\" >\n",
    "\n",
    "An orm works to negotiate between the language your are currently programming in and the relational storage system that you are using. Simplifying the amount of work that a programmer needs to do and allowing for greater levels of automation.\n",
    "\n",
    "i.e. lastName : object --> lastName : varchar(255) || Python --> PostgreSQL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ *by this point you should have your postgresql server running, have written down the information needed for connection and also ensured that you have **Pandas, Pyscopg2 and SQLalchemy installed** and accessible in your current env... if not. Please take this moment to do so.* ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to SQL ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlalchemy create_engine \n",
    "# this will be the main module we work with\n",
    "from sqlalchemy import create_engine\n",
    "# conda install anaconda::sqlalchemy\n",
    "\n",
    "\n",
    "# from sqlalchemy_utils import database_exists, create_database if you are automating DB creation\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "# conda install conda-forge::sqlalchemy-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "The start of any SQLAlchemy application is an object called the Engine. This object acts as a central source of connections to a particular database, providing both a factory as well as a holding space called a connection pool for these database connections. The engine is typically a global object created just once for a particular database server, and is configured using a URL string which will describe how it should connect to the database host or backend.\n",
    "\n",
    "### Function\n",
    "create_engine(*URL string*)\n",
    "### URL string\n",
    "examples:\n",
    "\n",
    "- postgresql://postgres:a@localhost:5435/test\n",
    "- mysql+pymysql://user:pass@some_mariadb/dbname?charset=utf8mb4\"\n",
    "\n",
    "breakdown:\n",
    "- type of DB (DBAPI):// user : password @ address : port / Database name ? extra params\n",
    "\n",
    "Acceptable Dialects:\n",
    "\n",
    "|||||\n",
    "|--- |--- |--- |--- |\n",
    "|Microsoft SQL Server|2017|2012+|2005+|\n",
    "|MySQL / MariaDB|5.6, 5.7, 8.0 / 10.8, 10.9|5.6+ / 10+|5.0.2+ / 5.0.2+|\n",
    "|Oracle|18c|11+|9+|\n",
    "|PostgreSQL|12, 13, 14, 15|9.6+|9+|\n",
    "|SQLite|3.36.0|3.12+|3.7.16+|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an engine using postgreSQL\n",
    "\n",
    "# setup logic for creating a database if wanted for automation otherwise manually create your DB\n",
    "# this logic will use the same URL String as described earlier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello world',)]\n"
     ]
    }
   ],
   "source": [
    "# getting back a hello world\n",
    "\n",
    "# in order to query against a DB import text from sqlalchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/sql1.png\" alt=\"MISSING\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence instructions and commit alterations manually\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/sql2.png\" alt=\"MISSING\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorperating pandas\n",
    "We will use pd.to_sql in order to bridge the gap between manual input and automagic inputs\n",
    "\n",
    "\n",
    "**df.to_sql(table name (str), connection (obj), if_exists (str), chunksize=int, index=bool)**\n",
    "\n",
    "[further documentation df.to_sql](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2 manual open and close\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More documentation...\n",
    "[dealing with disconnections](https://docs.sqlalchemy.org/en/20/core/pooling.html#dealing-with-disconnects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying your data\n",
    "[Furthering querying discussion](https://towardsdatascience.com/sqlalchemy-python-tutorial-79a577141a91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlalchemy.sql.schema.Table"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table('orders', MetaData(), Column('order_id', TEXT(), table=<orders>), Column('order_date', TEXT(), table=<orders>), Column('ship_date', TEXT(), table=<orders>), Column('ship_mode', TEXT(), table=<orders>), Column('customer_id', TEXT(), table=<orders>), Column('product_id', TEXT(), table=<orders>), Column('sales', DOUBLE_PRECISION(precision=53), table=<orders>), Column('quantity', BIGINT(), table=<orders>), Column('discount', DOUBLE_PRECISION(precision=53), table=<orders>), Column('profit', DOUBLE_PRECISION(precision=53), table=<orders>), Column('postal_code', DOUBLE_PRECISION(precision=53), table=<orders>), Column('region_id', DOUBLE_PRECISION(precision=53), table=<orders>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# printing the full metadata \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AE-2016-1308551', '2016-09-28', '2016-10-02', 'Second Class', 'PO-8865', 'OFF-FEL-10001405', 82.67, 2, 0.3, 0.3, None, 9954.0),\n",
       " ('AE-2016-1522857', '2016-09-04', '2016-09-09', 'Standard Class', 'PO-8865', 'TEC-EPS-10004171', 78.41, 6, 0.5, 0.5, None, 4792.0),\n",
       " ('AE-2016-184765', '2016-10-03', '2016-10-07', 'Second Class', 'PO-8865', 'OFF-FEL-10001405', 82.67, 2, 0.3, 0.3, None, 19848.0)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert query to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>region_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE-2016-1308551</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>PO-8865</td>\n",
       "      <td>OFF-FEL-10001405</td>\n",
       "      <td>82.67</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE-2016-1522857</td>\n",
       "      <td>2016-09-04</td>\n",
       "      <td>2016-09-09</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>PO-8865</td>\n",
       "      <td>TEC-EPS-10004171</td>\n",
       "      <td>78.41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE-2016-184765</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>PO-8865</td>\n",
       "      <td>OFF-FEL-10001405</td>\n",
       "      <td>82.67</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE-2016-1878215</td>\n",
       "      <td>2016-09-15</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>PO-8865</td>\n",
       "      <td>TEC-EPS-10004171</td>\n",
       "      <td>78.41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE-2016-218276</td>\n",
       "      <td>2016-10-09</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>PO-8865</td>\n",
       "      <td>TEC-EPS-10004171</td>\n",
       "      <td>78.41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1826.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  order_date   ship_date       ship_mode customer_id  \\\n",
       "0  AE-2016-1308551  2016-09-28  2016-10-02    Second Class     PO-8865   \n",
       "1  AE-2016-1522857  2016-09-04  2016-09-09  Standard Class     PO-8865   \n",
       "2   AE-2016-184765  2016-10-03  2016-10-07    Second Class     PO-8865   \n",
       "3  AE-2016-1878215  2016-09-15  2016-09-17  Standard Class     PO-8865   \n",
       "4   AE-2016-218276  2016-10-09  2016-10-12  Standard Class     PO-8865   \n",
       "\n",
       "         product_id  sales  quantity  discount  profit  postal_code  region_id  \n",
       "0  OFF-FEL-10001405  82.67         2       0.3     0.3          NaN     9954.0  \n",
       "1  TEC-EPS-10004171  78.41         6       0.5     0.5          NaN     4792.0  \n",
       "2  OFF-FEL-10001405  82.67         2       0.3     0.3          NaN    19848.0  \n",
       "3  TEC-EPS-10004171  78.41         6       0.5     0.5          NaN     1410.0  \n",
       "4  TEC-EPS-10004171  78.41         6       0.5     0.5          NaN     1826.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple schema work\n",
    "[lots of documentation furthering DDL discussion](https://docs.sqlalchemy.org/en/20/tutorial/metadata.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple push of the product table to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the entire products table and convert it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the products table with all types defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OYO Dissect and Refactor this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sys related imports\n",
    "from datetime import date, datetime, timedelta\n",
    "from distutils.command.clean import clean\n",
    "from time import timezone\n",
    "import pytz\n",
    "\n",
    "# api json related imports\n",
    "import requests\n",
    "\n",
    "# Data Handling imports\n",
    "import pandas as pd \n",
    "from pandas import json_normalize\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# DB Connection and Data Migration Imports\n",
    "from unicodedata import numeric\n",
    "from xmlrpc.client import DateTime\n",
    "from sqlalchemy import create_engine, DateTime, Column, Float, Integer, String, Date\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "\n",
    "def SearchDate():\n",
    "    '''\n",
    "    Checks to see if 8am cst has happened\n",
    "    if not then it pulls yesterday's results\n",
    "    if yes then it pulls todays results\n",
    "    this lines up with ESO's daily update\n",
    "    '''\n",
    "    time_zone = pytz.timezone('America/Chicago')\n",
    "    datetime_timezone = datetime.now(time_zone)\n",
    "    current_hour = int(datetime_timezone.strftime('%H'))\n",
    "\n",
    "    search_date = str(date.today()) if current_hour>8 else str(date.today()-timedelta(days=1))\n",
    "\n",
    "    return search_date\n",
    "\n",
    "\n",
    "def StarterURLGenerator():\n",
    "    '''\n",
    "    Creates an easier interface for making more complex\n",
    "    queries for KCAN api\n",
    "    in 'search_dictionary' add any known column and known \n",
    "    attribute that you want to query for in relivant data set\n",
    "    format == \"column header\" : \"known criterion\"\n",
    "\n",
    "    Only creates first needed URL\n",
    "    No pagination defeated in this function    \n",
    "    '''\n",
    "    search_dictionary = {\"EFA Date\":SearchDate(), \"Company\":\"HABITAT ENERGY LIMITED\"}\n",
    "    resource_id = \"ddc4afde-d2bd-424d-891c-56ad49c13d1a\"\n",
    "\n",
    "    dictionary_list = [ '\"'+param[0]+'\":\"'+param[1]+'\"' for param in search_dictionary.items()]\n",
    "    dictionary_string = '{'+','.join(dictionary_list)+'}'\n",
    "\n",
    "    starting_api = '/api/3/action/datastore_search?q='+dictionary_string+'&resource_id='+resource_id\n",
    "\n",
    "\n",
    "    return starting_api\n",
    "\n",
    "\n",
    "def ApiScraper(links, rawdf, domain):\n",
    "    # Moving through the links\n",
    "    link = links[-1]\n",
    "    request = requests.get(domain+link)\n",
    "    if request.status_code == 200:\n",
    "        json = request.json()\n",
    "        \n",
    "        # Stop if there are no records returned\n",
    "        if json['result']['records'] == []:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # adding results to rawdf\n",
    "        df = json_normalize(json['result']['records'])\n",
    "\n",
    "        # store next link from json\n",
    "        links.append(json['result']['_links']['next'])\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        raise 'Response Code: '+str(request.status_code)\n",
    "\n",
    "\n",
    "def Cleaner(rawdf):\n",
    "    df = pd.DataFrame(rawdf).astype({\n",
    "    \"_id\": int, \n",
    "    \"Company\": object,\n",
    "    \"Unit Name\": object,  \n",
    "    \"EFA\":int,  \n",
    "    \"Service\":object,\n",
    "    \"Cleared Volume\": float,\n",
    "    \"Clearing Price\": float,\n",
    "    \"Technology Type\": object,\n",
    "    \"Cancelled\": object\n",
    "    })\n",
    "\n",
    "    # Handling dates\n",
    "    df['EFA Date'] = pd.to_datetime(df['EFA Date'])\n",
    "    df['Delivery End'] = pd.to_datetime(df['Delivery End'])\n",
    "    df['Delivery Start'] = pd.to_datetime(df['Delivery Start'])\n",
    "\n",
    "    # Lowering texts and removing spaces\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace(\" \", \"\")\n",
    "\n",
    "    return df\n",
    "  \n",
    "\n",
    "def EngineGenerator():\n",
    "    loginAttempt = True\n",
    "    while loginAttempt:\n",
    "        try:\n",
    "            print('-'*20)\n",
    "            print('PostgreSQL Server Login Information:')\n",
    "            username = str(input('Enter Username (Default: postgres)\\n>')).strip()\n",
    "            password = str(input('Enter Password (Default: None)\\n>')).strip()\n",
    "            host_address = str(input('Enter Host Address (Default: localhost)\\n>')).strip()\n",
    "            port = str(input('Enter Port (Default: 5432)\\n>')).strip()\n",
    "            database_name = str(input('Enter Database Name (Default: habitat)\\n>')).strip()\n",
    "\n",
    "            engine_string = 'postgresql://'\n",
    "\n",
    "            defaults = ['','postgres', '', '', '@','localhost', ':','5432', '/','habitat']\n",
    "            user_input = ['', username, ':', password, '@', host_address, ':', port, '/', database_name]\n",
    "            \n",
    "            for i in range(0,len(defaults),2):\n",
    "                if user_input[i+1] == '':\n",
    "                    engine_string += defaults[i]+defaults[i+1]\n",
    "                else:\n",
    "                    engine_string += user_input[i]+user_input[i+1]\n",
    "            \n",
    "            engine = create_engine(engine_string, echo=False)\n",
    "\n",
    "            if not database_exists(engine.url):\n",
    "                create_database(engine.url)\n",
    "            \n",
    "            loginAttempt = False\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            tryagain = input('\\n\\n>>Try Again<<\\n(Y/N) >> ')\n",
    "            if tryagain.upper() == 'N':\n",
    "                raise 'Could Not Login To PostgreSQL Server'\n",
    "    print('-'*20)\n",
    "    print('PostgreSQL Server Connection Successful\\n', engine_string)\n",
    "    return engine\n",
    "\n",
    "\n",
    "def DatabaseHandler(df):\n",
    "    # Creating engine, Database and allowing for Schema definition\n",
    "    engine = EngineGenerator()\n",
    "\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    # Define schema and migrate information \n",
    "    # OR\n",
    "    # Append newly scraped information\n",
    "\n",
    "    try:\n",
    "        Base = declarative_base()\n",
    "\n",
    "        class eso_auction_results_habitat_schema(Base):\n",
    "            __tablename__ = 'eso_auction_results_habitat'\n",
    "            _id = Column(Integer, primary_key=True) \n",
    "            company = Column(String[50])\n",
    "            unitname = Column(String)\n",
    "            efadate = Column(DateTime())\n",
    "            deliverystart = Column(DateTime())\n",
    "            deliveryend = Column(DateTime())\n",
    "            efa = Column(Integer)\n",
    "            service = Column(String)\n",
    "            clearedvolume = Column(Float)\n",
    "            clearingprice = Column(Float)\n",
    "            technologytype = Column(String) \n",
    "            location = Column(String)\n",
    "            cancelled = Column(String)\n",
    "            rankefadate = Column(Float)\n",
    "            rankcompany = Column(Float)\n",
    "            \n",
    "        Base.metadata.create_all(engine)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        df.to_sql('eso_auction_results_habitat', con=engine, if_exists='append', index =False)\n",
    "    except Exception as e:\n",
    "        print(\">> Error >> No New Values Added To Database <<\")\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "    links = [StarterURLGenerator()]\n",
    "    rawdf = pd.DataFrame()\n",
    "    domain = 'https://data.nationalgrideso.com'\n",
    "    cont = True\n",
    "\n",
    "    # ApiScaper Iterator\n",
    "    while cont:\n",
    "        tempdf = ApiScraper(links, rawdf, domain)\n",
    "        if tempdf.shape[0]>0: \n",
    "            rawdf = pd.concat([rawdf, tempdf])\n",
    "        else:\n",
    "            cont=False\n",
    "    \n",
    "    print('\\nApiScraper: True\\n')\n",
    "\n",
    "    clean_df = Cleaner(rawdf)\n",
    "    # Creating long term storage version of df\n",
    "    clean_df.to_csv(\"df\", index = False)\n",
    "\n",
    "    DatabaseHandler(clean_df)\n",
    "    print('\\nDatabaseHandler: Successful\\n')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d13536f891b664e8b0f3176c7c1010cc08ef4d822c857a45970b08f820c823d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
